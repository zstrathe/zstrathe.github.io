{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjs7vedQhGZ_",
        "outputId": "d1ccbed1-6465-4db3-91e7-baa2616d51a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Page: http://www.azlyrics.com/w/wonder.html - scraped 330 song URLs\n",
            "Page: http://www.azlyrics.com/b/bowie.html - scraped 368 song URLs\n",
            "Page: http://www.azlyrics.com/t/tool.html - scraped 72 song URLs\n",
            "Page: http://www.azlyrics.com/n/nine.html - scraped 127 song URLs\n",
            "Page: http://www.azlyrics.com/m/metallica.html - scraped 162 song URLs\n",
            "Page: http://www.azlyrics.com/b/blacksabbath.html - scraped 206 song URLs\n",
            "Page: http://www.azlyrics.com/j/jayz.html - scraped 278 song URLs\n",
            "Page: http://www.azlyrics.com/f/frankzappa.html - scraped 563 song URLs\n",
            "Attempting to scrape lyrics from 248 total songs\n",
            "Collecting from page:  1\n",
            "Collecting from page:  2\n",
            "Collecting from page:  3\n",
            "Collecting from page:  4\n",
            "Connection failure?\n",
            "Waiting 10 seconds to retry.\n",
            "Collecting from page:  4\n",
            "Collecting from page:  5\n",
            "Collecting from page:  6\n",
            "Collecting from page:  7\n",
            "Collecting from page:  8\n",
            "Collecting from page:  9\n",
            "Collecting from page:  10\n",
            "Collecting from page:  11\n",
            "Collecting from page:  12\n",
            "Collecting from page:  13\n",
            "Collecting from page:  14\n",
            "Collecting from page:  15\n",
            "Collecting from page:  16\n",
            "Collecting from page:  17\n",
            "Collecting from page:  18\n",
            "Collecting from page:  19\n",
            "Collecting from page:  20\n",
            "Collecting from page:  21\n",
            "Collecting from page:  22\n",
            "Collecting from page:  23\n",
            "Collecting from page:  24\n",
            "Collecting from page:  25\n",
            "Collecting from page:  26\n",
            "Collecting from page:  27\n",
            "Collecting from page:  28\n",
            "Collecting from page:  29\n",
            "Collecting from page:  30\n",
            "Collecting from page:  31\n",
            "Collecting from page:  32\n",
            "Collecting from page:  33\n",
            "Collecting from page:  34\n",
            "Collecting from page:  35\n",
            "Collecting from page:  36\n",
            "Collecting from page:  37\n",
            "Collecting from page:  38\n",
            "Collecting from page:  39\n",
            "Collecting from page:  40\n",
            "Collecting from page:  41\n",
            "Collecting from page:  42\n",
            "Collecting from page:  43\n",
            "Collecting from page:  44\n",
            "Collecting from page:  45\n",
            "Collecting from page:  46\n",
            "Collecting from page:  47\n",
            "Collecting from page:  48\n",
            "Collecting from page:  49\n",
            "Collecting from page:  50\n",
            "Collecting from page:  51\n",
            "Collecting from page:  52\n",
            "Collecting from page:  53\n",
            "Collecting from page:  54\n",
            "Collecting from page:  55\n",
            "Collecting from page:  56\n",
            "Collecting from page:  57\n",
            "Collecting from page:  58\n",
            "Collecting from page:  59\n",
            "Collecting from page:  60\n",
            "Collecting from page:  61\n",
            "Collecting from page:  62\n",
            "Collecting from page:  63\n",
            "Collecting from page:  64\n",
            "Collecting from page:  65\n",
            "Collecting from page:  66\n",
            "Collecting from page:  67\n",
            "Collecting from page:  68\n",
            "Collecting from page:  69\n",
            "Collecting from page:  70\n",
            "Collecting from page:  71\n",
            "Collecting from page:  72\n",
            "Collecting from page:  73\n",
            "Collecting from page:  74\n",
            "Collecting from page:  75\n",
            "Collecting from page:  76\n",
            "Collecting from page:  77\n",
            "Collecting from page:  78\n",
            "Collecting from page:  79\n",
            "Collecting from page:  80\n",
            "Collecting from page:  81\n",
            "Collecting from page:  82\n",
            "Collecting from page:  83\n",
            "Collecting from page:  84\n",
            "Collecting from page:  85\n",
            "Collecting from page:  86\n",
            "Collecting from page:  87\n",
            "Collecting from page:  88\n",
            "Collecting from page:  89\n",
            "Collecting from page:  90\n",
            "Collecting from page:  91\n",
            "Collecting from page:  92\n",
            "Collecting from page:  93\n",
            "Collecting from page:  94\n",
            "Collecting from page:  95\n",
            "Collecting from page:  96\n",
            "Collecting from page:  97\n",
            "Collecting from page:  98\n",
            "Collecting from page:  99\n",
            "Collecting from page:  100\n",
            "Collecting from page:  101\n",
            "Collecting from page:  102\n",
            "Collecting from page:  103\n",
            "Collecting from page:  104\n",
            "Blocked?\n",
            "Press any key to try again, or 'skip' to continue to next song.nj\n",
            "Collecting from page:  104\n",
            "Connection failure?\n",
            "Waiting 10 seconds to retry.\n",
            "Collecting from page:  104\n",
            "Collecting from page:  105\n",
            "Collecting from page:  106\n",
            "Collecting from page:  107\n",
            "Collecting from page:  108\n",
            "Collecting from page:  109\n",
            "Collecting from page:  110\n",
            "Collecting from page:  111\n",
            "Collecting from page:  112\n",
            "Collecting from page:  113\n",
            "Collecting from page:  114\n",
            "Collecting from page:  115\n",
            "Collecting from page:  116\n",
            "Collecting from page:  117\n",
            "Collecting from page:  118\n",
            "Collecting from page:  119\n",
            "Collecting from page:  120\n",
            "Collecting from page:  121\n",
            "Collecting from page:  122\n",
            "Collecting from page:  123\n",
            "Collecting from page:  124\n",
            "Collecting from page:  125\n",
            "Collecting from page:  126\n",
            "Collecting from page:  127\n",
            "Collecting from page:  128\n",
            "Collecting from page:  129\n",
            "Collecting from page:  130\n",
            "Collecting from page:  131\n",
            "Collecting from page:  132\n",
            "Collecting from page:  133\n",
            "Collecting from page:  134\n",
            "Collecting from page:  135\n",
            "Collecting from page:  136\n",
            "Collecting from page:  137\n",
            "Collecting from page:  138\n",
            "Collecting from page:  139\n",
            "Collecting from page:  140\n",
            "Collecting from page:  141\n",
            "Collecting from page:  142\n",
            "Collecting from page:  143\n",
            "Collecting from page:  144\n",
            "Collecting from page:  145\n",
            "Collecting from page:  146\n",
            "Collecting from page:  147\n",
            "Collecting from page:  148\n",
            "Collecting from page:  149\n",
            "Collecting from page:  150\n",
            "Collecting from page:  151\n",
            "Collecting from page:  152\n",
            "Collecting from page:  153\n",
            "Collecting from page:  154\n",
            "Collecting from page:  155\n",
            "Collecting from page:  156\n",
            "Collecting from page:  157\n",
            "Collecting from page:  158\n",
            "Collecting from page:  159\n",
            "Collecting from page:  160\n",
            "Collecting from page:  161\n",
            "Collecting from page:  162\n",
            "Collecting from page:  163\n",
            "Collecting from page:  164\n",
            "Collecting from page:  165\n",
            "Collecting from page:  166\n",
            "Collecting from page:  167\n",
            "Collecting from page:  168\n",
            "Collecting from page:  169\n",
            "Collecting from page:  170\n",
            "Collecting from page:  171\n",
            "Collecting from page:  172\n",
            "Collecting from page:  173\n",
            "Collecting from page:  174\n",
            "Collecting from page:  175\n",
            "Collecting from page:  176\n",
            "Collecting from page:  177\n",
            "Collecting from page:  178\n",
            "Collecting from page:  179\n",
            "Collecting from page:  180\n",
            "Collecting from page:  181\n",
            "Collecting from page:  182\n",
            "Collecting from page:  183\n",
            "Collecting from page:  184\n",
            "Collecting from page:  185\n",
            "Collecting from page:  186\n",
            "Collecting from page:  187\n",
            "Collecting from page:  188\n",
            "Collecting from page:  189\n",
            "Collecting from page:  190\n",
            "Collecting from page:  191\n",
            "Collecting from page:  192\n",
            "Collecting from page:  193\n",
            "Collecting from page:  194\n",
            "Collecting from page:  195\n",
            "Collecting from page:  196\n",
            "Collecting from page:  197\n",
            "Collecting from page:  198\n",
            "Collecting from page:  199\n",
            "Collecting from page:  200\n",
            "Collecting from page:  201\n",
            "Collecting from page:  202\n",
            "Collecting from page:  203\n",
            "Collecting from page:  204\n",
            "Blocked?\n",
            "Press any key to try again, or 'skip' to continue to next song.ny\n",
            "Collecting from page:  204\n",
            "Collecting from page:  205\n",
            "Collecting from page:  206\n",
            "Collecting from page:  207\n",
            "Collecting from page:  208\n",
            "Collecting from page:  209\n",
            "Collecting from page:  210\n",
            "Collecting from page:  211\n",
            "Collecting from page:  212\n",
            "Collecting from page:  213\n",
            "Collecting from page:  214\n",
            "Collecting from page:  215\n",
            "Collecting from page:  216\n",
            "Collecting from page:  217\n",
            "Connection failure?\n",
            "Waiting 10 seconds to retry.\n",
            "Collecting from page:  217\n",
            "Connection failure?\n",
            "Waiting 10 seconds to retry.\n",
            "Collecting from page:  217\n",
            "Collecting from page:  218\n",
            "Collecting from page:  219\n",
            "Collecting from page:  220\n",
            "Collecting from page:  221\n",
            "Collecting from page:  222\n",
            "Collecting from page:  223\n",
            "Collecting from page:  224\n",
            "Collecting from page:  225\n",
            "Collecting from page:  226\n",
            "Collecting from page:  227\n",
            "Collecting from page:  228\n",
            "Collecting from page:  229\n",
            "Collecting from page:  230\n",
            "Collecting from page:  231\n",
            "Blocked?\n",
            "Press any key to try again, or 'skip' to continue to next song.nn\n",
            "Collecting from page:  231\n",
            "Blocked?\n",
            "Press any key to try again, or 'skip' to continue to next song.nd\n",
            "Collecting from page:  231\n",
            "Blocked?\n",
            "Press any key to try again, or 'skip' to continue to next song.ng\n",
            "Collecting from page:  231\n",
            "Blocked?\n",
            "Press any key to try again, or 'skip' to continue to next song.nskip\n",
            "Skipping page 231: http://www.azlyrics.com//www.google.com/search?q=Tool+lyrics+Message+To+Harry+Manback\n",
            "Collecting from page:  232\n",
            "Collecting from page:  233\n",
            "Collecting from page:  234\n",
            "Collecting from page:  235\n",
            "Collecting from page:  236\n",
            "Collecting from page:  237\n",
            "Collecting from page:  238\n",
            "Collecting from page:  239\n",
            "Collecting from page:  240\n",
            "Collecting from page:  241\n",
            "Collecting from page:  242\n",
            "Collecting from page:  243\n",
            "Collecting from page:  244\n",
            "Collecting from page:  245\n",
            "Collecting from page:  246\n",
            "Collecting from page:  247\n",
            "Collecting from page:  248\n",
            "Finished scraping 247 song lyrics. Encountered 1 errors.\n"
          ]
        }
      ],
      "source": [
        "##############################\n",
        "## Web scraping song lyrics ##\n",
        "##############################\n",
        "\n",
        "import requests\n",
        "from lxml import html\n",
        "import random\n",
        "import time\n",
        "\n",
        "# list of urls to scrape song lyrics from\n",
        "web_list = ['http://www.azlyrics.com/w/wonder.html',\n",
        "            'http://www.azlyrics.com/b/bowie.html', \n",
        "            'http://www.azlyrics.com/t/tool.html',\n",
        "            'http://www.azlyrics.com/n/nine.html',\n",
        "            'http://www.azlyrics.com/m/metallica.html',\n",
        "            'http://www.azlyrics.com/b/blacksabbath.html',\n",
        "            'http://www.azlyrics.com/j/jayz.html',\n",
        "            'http://www.azlyrics.com/f/frankzappa.html'\n",
        "           ] \n",
        "\n",
        "# Initialize a blank output file (and overwrite any existing file)\n",
        "with open('scraped_lyrics.txt', 'w') as output_file:\n",
        "    output_file.write('')\n",
        "    \n",
        "random.seed(554646)\n",
        "# first scrape the links to each song \n",
        "url_list = []\n",
        "for page in web_list:\n",
        "    artist_songlist = []\n",
        "    data = html.fromstring(requests.get(page).text)\n",
        "    for song in data.xpath(\"//div[@class='listalbum-item']\"):\n",
        "        url = song.xpath(\"a/@href\")\n",
        "        if len(url) > 0:\n",
        "            if url[0].startswith('https://www.') == False:\n",
        "                url = 'http://www.azlyrics.com' + url[0]\n",
        "                artist_songlist.append(url)\n",
        "    random.shuffle(artist_songlist)\n",
        "    print(f'Page: {page} - scraped {len(artist_songlist)} song URLs')\n",
        "    [url_list.append(i) for i in artist_songlist[:31]]\n",
        "    time.sleep(5)\n",
        "\n",
        "print(f'Attempting to scrape lyrics from {len(url_list)} total songs')\n",
        "random.shuffle(url_list)\n",
        "scraped_count = 0\n",
        "for i in range(len(url_list)):\n",
        "    successful = False\n",
        "    connection_error_count = 0\n",
        "    while not successful:\n",
        "        print('Collecting from page: ', i+1)\n",
        "        try:\n",
        "            data = html.fromstring(requests.get(url_list[i]).text)\n",
        "            lyrics_count = 0\n",
        "            for lyric in data.xpath(\"//div[contains(@class,'text-center')]\"):\n",
        "                lyrics = lyric.xpath(\"div[5]/text()\")\n",
        "                if len(lyric) > 1:\n",
        "                    for line in lyrics:\n",
        "                        if len(line.strip()) > 0:\n",
        "                            with open('scraped_lyrics.txt', 'a') as output_file:\n",
        "                                try:\n",
        "                                    output_file.write(str(line.strip()) + '\\n')\n",
        "                                    lyrics_count += 1\n",
        "                                    successful = True\n",
        "                                except: \n",
        "                                    continue\n",
        "            if lyrics_count == 0: \n",
        "                print('Blocked?')\n",
        "                x = input(\"Press any key to try again, or 'skip' to continue to next song.\")\n",
        "                if x == 'skip':\n",
        "                    print(f'Skipping page {i+1}: {url_list[i]}')\n",
        "                    successful = True\n",
        "                else:\n",
        "                    continue\n",
        "            else:\n",
        "                scraped_count += 1\n",
        "                time.sleep(5) # timer to avoid being ip blocked \n",
        "        except:\n",
        "            print('Connection failure?')\n",
        "            connection_error_count += 1\n",
        "            if connection_error_count >= 3: \n",
        "                print(f'Skipping page {i+1}: {url_list[i]}')\n",
        "                successful = True\n",
        "            else:\n",
        "                print('Waiting 10 seconds to retry.')\n",
        "                time.sleep(10)\n",
        "\n",
        "print(f'Finished scraping {scraped_count} song lyrics. Encountered {len(url_list) - scraped_count} errors.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "qN39X9YkhGaP"
      },
      "outputs": [],
      "source": [
        "list1 = []\n",
        "list2 = []\n",
        "    \n",
        "f = open(\"full_corpus.txt\", \"r\")\n",
        "text = f.readlines()\n",
        "#print(len(text))\n",
        "text = list(dict.fromkeys(text)) # remove duplicate\n",
        "with open('full_corpus_no_dups.txt', 'w') as output_file:\n",
        "    [output_file.write(i) for i in text]\n",
        "    \n",
        "lines_text = len(text)\n",
        "#print(len(text))\n",
        "counter = 0\n",
        "while lines_text > 0:\n",
        "    for i in range(2):\n",
        "        if i == 0:\n",
        "            list1.append(text[counter])\n",
        "            lines_text -= 1\n",
        "            counter += 1\n",
        "        if i == 1:\n",
        "            list2.append(text[counter])\n",
        "            lines_text -= 1\n",
        "            counter += 1\n",
        "#print(len(list1), len(list2)) # print lengths of each list to check that they're equal\n",
        "with open('train.tgt', 'w') as output_file:\n",
        "    [output_file.write(i) for i in list1]\n",
        "with open('train.txt', 'w') as output_file:\n",
        "    [output_file.write(i) for i in list1]\n",
        "with open('test.tgt', 'w') as output_file: # test and valid datasets should be the same per COCO example in github repo\n",
        "    [output_file.write(i) for i in list2]\n",
        "with open('test.txt', 'w') as output_file: \n",
        "    [output_file.write(i) for i in list2]\n",
        "with open('valid.tgt', 'w') as output_file: # test and valid datasets should be the same per COCO example in github repo\n",
        "    [output_file.write(i) for i in list2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqDGPDTzhGaS",
        "outputId": "bd9a7ad1-6e4d-4670-ef61-ae2b21a22992"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "The average length of a line in the text is:  7.872226472838562\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "counter = 0\n",
        "length = 0\n",
        "with open('full_corpus_no_dups.txt') as text_file:\n",
        "    for line in text_file:\n",
        "        tokens = word_tokenize(line)\n",
        "        length += len(tokens)\n",
        "        counter += 1\n",
        "avglen = length/counter\n",
        "print(f'The average length of a line in the text is:  {avglen}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MvJY27ahGaV"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "WebScraping_SongLyrics.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}